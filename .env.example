# ============================================================================
# Code Executor MCP - Environment Configuration Example
# ============================================================================
# Copy this file to .env and fill in your actual values
# NEVER commit .env to git - it's already in .gitignore
# ============================================================================

# ----------------------------------------------------------------------------
# SAMPLING CONFIGURATION (Optional - MCP works without sampling)
# ----------------------------------------------------------------------------

# Enable AI sampling feature (default: false)
# Set to true to enable LLM callbacks in sandboxed code
CODE_EXECUTOR_SAMPLING_ENABLED=false

# Select AI provider (options: anthropic, openai, gemini, grok, perplexity)
# Default: anthropic
CODE_EXECUTOR_AI_PROVIDER=gemini

# ----------------------------------------------------------------------------
# API KEYS (Provider-specific - only needed if sampling is enabled)
# ----------------------------------------------------------------------------
# Get your keys from:
# - Anthropic: https://console.anthropic.com/settings/keys
# - OpenAI: https://platform.openai.com/api-keys
# - Gemini: https://aistudio.google.com/app/apikey
# - Grok: https://console.x.ai/
# - Perplexity: https://www.perplexity.ai/settings/api

# Anthropic Claude API key
# ANTHROPIC_API_KEY=sk-ant-xxxxx

# OpenAI GPT API key
# OPENAI_API_KEY=sk-xxxxx

# Google Gemini API key
GEMINI_API_KEY=your-gemini-key-here

# xAI Grok API key
# GROK_API_KEY=xxxxx

# Perplexity API key
# PERPLEXITY_API_KEY=xxxxx

# Custom base URL for OpenAI-compatible providers (optional)
# Useful for Grok, Perplexity, or custom OpenAI proxies
# CODE_EXECUTOR_AI_BASE_URL=https://api.x.ai/v1

# ----------------------------------------------------------------------------
# MODEL CONFIGURATION
# ----------------------------------------------------------------------------

# Allowed models (comma-separated list for security)
# Default: Latest cost-effective models for each provider (January 2025)
# Anthropic: claude-haiku-4-5-20251001 ($1/$5 per MTok)
# OpenAI: gpt-4o-mini ($0.15/$0.60 per MTok)
# Gemini: gemini-2.5-flash-lite ($0.10/$0.40 per MTok) - CHEAPEST!
# Grok: grok-4-1-fast-non-reasoning ($0.20/$0.50 per MTok)
# Perplexity: sonar ($1/$1 per MTok)
# CODE_EXECUTOR_ALLOWED_MODELS=gemini-2.5-flash-lite,gemini-2.5-flash,gemini-2.5-pro,gpt-4o-mini,claude-haiku-4-5-20251001

# ----------------------------------------------------------------------------
# RATE LIMITING & QUOTAS
# ----------------------------------------------------------------------------

# Maximum sampling rounds per execution (default: 10, range: 1-100)
# Prevents infinite loops in LLM callback chains
CODE_EXECUTOR_MAX_SAMPLING_ROUNDS=10

# Maximum tokens per execution (default: 10000, range: 100-100000)
# Controls total token usage across all sampling rounds
CODE_EXECUTOR_MAX_SAMPLING_TOKENS=10000

# Timeout per sampling call in milliseconds (default: 30000ms = 30s)
# Range: 1000ms (1s) to 600000ms (10min)
CODE_EXECUTOR_SAMPLING_TIMEOUT_MS=30000

# ----------------------------------------------------------------------------
# SECURITY & VALIDATION
# ----------------------------------------------------------------------------

# Allowed system prompts (comma-separated for security)
# Default: empty prompt, helpful assistant, code analysis expert
# CODE_EXECUTOR_ALLOWED_SYSTEM_PROMPTS=,You are a helpful assistant,You are a code analysis expert

# Enable content filtering for secrets/PII (default: true)
# Filters out API keys, tokens, passwords from LLM responses
CODE_EXECUTOR_CONTENT_FILTERING_ENABLED=true

# ----------------------------------------------------------------------------
# GENERAL MCP SERVER CONFIGURATION
# ----------------------------------------------------------------------------

# Server port for HTTP transport (default: 3000)
# MCP_SERVER_PORT=3000

# Execution timeout in milliseconds (default: 120000ms = 2min)
# Maximum time for code execution before timeout
# CODE_EXECUTOR_TIMEOUT_MS=120000

# Audit log path (default: ~/.code-executor/audit.log)
# Logs all tool executions for security auditing
# CODE_EXECUTOR_AUDIT_LOG_PATH=/path/to/audit.log

# Schema cache TTL in milliseconds (default: 86400000ms = 24h)
# How long to cache MCP tool schemas before refreshing
# CODE_EXECUTOR_SCHEMA_CACHE_TTL_MS=86400000

# ----------------------------------------------------------------------------
# DOCKER & DEPLOYMENT
# ----------------------------------------------------------------------------

# Set to true if running in Docker container
# DOCKER_CONTAINER=false

# Node environment (development, production)
# NODE_ENV=development

# ----------------------------------------------------------------------------
# QUICK START EXAMPLES
# ----------------------------------------------------------------------------

# Example 1: Gemini (Cheapest - $0.10/$0.40 per MTok)
# CODE_EXECUTOR_SAMPLING_ENABLED=true
# CODE_EXECUTOR_AI_PROVIDER=gemini
# GEMINI_API_KEY=your-key-here

# Example 2: OpenAI (Budget-friendly - $0.15/$0.60 per MTok)
# CODE_EXECUTOR_SAMPLING_ENABLED=true
# CODE_EXECUTOR_AI_PROVIDER=openai
# OPENAI_API_KEY=sk-xxxxx

# Example 3: Anthropic (Premium - $1/$5 per MTok)
# CODE_EXECUTOR_SAMPLING_ENABLED=true
# CODE_EXECUTOR_AI_PROVIDER=anthropic
# ANTHROPIC_API_KEY=sk-ant-xxxxx

# Example 4: Grok (Fast & Cheap - $0.20/$0.50 per MTok, 2M context)
# CODE_EXECUTOR_SAMPLING_ENABLED=true
# CODE_EXECUTOR_AI_PROVIDER=grok
# GROK_API_KEY=xxxxx

# Example 5: Perplexity (Real-time search - $1/$1 per MTok)
# CODE_EXECUTOR_SAMPLING_ENABLED=true
# CODE_EXECUTOR_AI_PROVIDER=perplexity
# PERPLEXITY_API_KEY=xxxxx

# ----------------------------------------------------------------------------
# COST COMPARISON (January 2025)
# ----------------------------------------------------------------------------
# Provider    | Model                          | Input/MTok | Output/MTok | Total
# ------------|--------------------------------|------------|-------------|-------
# Gemini      | gemini-2.5-flash-lite         | $0.10      | $0.40       | $0.50 ⭐
# Grok        | grok-4-1-fast-non-reasoning   | $0.20      | $0.50       | $0.70
# OpenAI      | gpt-4o-mini                   | $0.15      | $0.60       | $0.75
# Perplexity  | sonar                         | $1.00      | $1.00       | $2.00
# Anthropic   | claude-haiku-4-5-20251001     | $1.00      | $5.00       | $6.00
#
# ⭐ Gemini is the most cost-effective option! Plus FREE tier in AI Studio.
# ----------------------------------------------------------------------------

# ----------------------------------------------------------------------------
# TROUBLESHOOTING
# ----------------------------------------------------------------------------
# Issue: "Sampling disabled" warning
# Solution: Set CODE_EXECUTOR_SAMPLING_ENABLED=true and add API key
#
# Issue: "Model not in allowlist" error
# Solution: Add your model to CODE_EXECUTOR_ALLOWED_MODELS
#
# Issue: "Rate limit exceeded"
# Solution: Increase CODE_EXECUTOR_MAX_SAMPLING_ROUNDS or TOKENS
#
# Issue: API key not loading
# Solution: Verify .env is in project root and variable name matches above
#
# Issue: "Provider not supported" error
# Solution: Check CODE_EXECUTOR_AI_PROVIDER spelling (case-sensitive)
# ----------------------------------------------------------------------------
